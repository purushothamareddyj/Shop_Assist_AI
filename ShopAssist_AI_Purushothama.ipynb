{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90bb1e2a",
      "metadata": {
        "id": "90bb1e2a"
      },
      "source": [
        "# ShopAssist AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7870d75-b40a-4704-aab3-a1bc1ae5fe98",
      "metadata": {
        "id": "a7870d75-b40a-4704-aab3-a1bc1ae5fe98"
      },
      "source": [
        "### Installing Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l7BLDeM5MXrC",
      "metadata": {
        "id": "l7BLDeM5MXrC"
      },
      "outputs": [],
      "source": [
        "# Install OpenAI library\n",
        "# !pip install -U -q openai tenacity pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b8a75b-cea1-4e46-9ae0-ca3a68014b1d",
      "metadata": {
        "id": "91b8a75b-cea1-4e46-9ae0-ca3a68014b1d"
      },
      "source": [
        "### Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c025125d-4357-45ab-8fa9-b36e7f30ba86",
      "metadata": {
        "id": "c025125d-4357-45ab-8fa9-b36e7f30ba86"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "import openai\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b7f54e-8700-4630-b5a3-5af7f8d0bcf9",
      "metadata": {
        "id": "35b7f54e-8700-4630-b5a3-5af7f8d0bcf9"
      },
      "outputs": [],
      "source": [
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5876b96f-088a-4cbf-bbf7-f823df43ded0",
      "metadata": {
        "id": "5876b96f-088a-4cbf-bbf7-f823df43ded0"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.width', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254126a6-912a-4659-85ae-f35b11f0e7e9",
      "metadata": {
        "id": "254126a6-912a-4659-85ae-f35b11f0e7e9"
      },
      "source": [
        "### Reading OpenAI Key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935d08d2-3a75-48b6-b864-aebd18517f5c",
      "metadata": {
        "id": "935d08d2-3a75-48b6-b864-aebd18517f5c"
      },
      "source": [
        "##### Make sure to keep a file by name `API_KEY` in which API key will be present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8c8768-6ffa-4b2e-a905-24cd7514f262",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7d8c8768-6ffa-4b2e-a905-24cd7514f262"
      },
      "outputs": [],
      "source": [
        "api_key_filename = \"API_KEY\"\n",
        "\n",
        "if os.path.isfile(api_key_filename):\n",
        "    with open(api_key_filename, \"r\") as f:\n",
        "        API_KEY = f.readline()\n",
        "else:\n",
        "    raise FileNotFoundError(f\"No file by name {api_key_filename} found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2150c50-1a9d-4e69-9f9a-e7a798590be7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "b2150c50-1a9d-4e69-9f9a-e7a798590be7",
        "outputId": "63dc45de-fbf5-4347-abfd-61ebfa82ba7f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'API_KEY' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-157857938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'API_KEY' is not defined"
          ]
        }
      ],
      "source": [
        "openai.api_key = API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29adca8b",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "29adca8b"
      },
      "outputs": [],
      "source": [
        "data_source_file = '/content/laptop_data (1).csv'\n",
        "if os.path.isfile(data_source_file):\n",
        "    df = pd.read_csv(data_source_file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\"No file by name {data_source_file} found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa79753-436e-4040-9afd-d994ab272953",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "faa79753-436e-4040-9afd-d994ab272953",
        "outputId": "ee8b4fb8-0654-43dc-9f5b-72b3d16c2faa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Apple\",\n          \"MSI\",\n          \"Acer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Inspiron\",\n          \"ENVY x360\",\n          \"ZenBook 13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Core\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"i7\",\n          \"Ryzen 5\",\n          \"i5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPU Manufacturer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Intel\",\n          \"AMD\",\n          \"Apple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clock Speed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2.9 GHz\",\n          \"2.6 GHz\",\n          \"1.6 GHz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"16GB\",\n          \"32GB\",\n          \"64GB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SSD\",\n          \"HDD+SSD\",\n          \"HDD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Display Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"IPS\",\n          \"PixelSense\",\n          \"LCD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Display Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"15.6\\\"\",\n          \"14\\\"\",\n          \"16\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Graphics Processor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"NVIDIA GTX\",\n          \"Apple M1\",\n          \"Intel UHD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen Resolution\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1920x1080\",\n          \"1366x768\",\n          \"2560x1600\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Windows 11\",\n          \"Ubuntu\",\n          \"Linux\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Laptop Weight\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"2.5 kg\",\n          \"2.3 kg\",\n          \"2.1 kg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Special Features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Backlit Keyboard\",\n          \"Dual Cooling Fans\",\n          \"Fingerprint Reader\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Warranty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1 year\",\n          \"2 years\",\n          \"3 years\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Battery Life\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"14 hours\",\n          \"4 hours\",\n          \"10 hours\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"35,000\",\n          \"55,000\",\n          \"85,000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\\\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\",\n          \"The HP ENVY x360 is a versatile 2-in-1 convertible laptop that combines performance and flexibility. It features an Intel Core i7 processor running at 2.8 GHz, providing powerful processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage space. The laptop features a 15.6\\\" IPS display with a resolution of 1920x1080, delivering vibrant visuals and wide viewing angles. It comes with Intel Iris Xe integrated graphics for smooth graphics performance. Weighing 2.05 kg, it offers a good balance between portability and functionality. The laptop features a convertible design, allowing you to switch between laptop and tablet modes for enhanced versatility. With a one-year warranty and a battery life of up to 7 hours, the HP ENVY x360 offers reliability and endurance for everyday use. Priced at 80,000, it provides a versatile computing experience at an affordable price point.\",\n          \"The ASUS ZenBook 13 is a lightweight and powerful laptop that offers a premium computing experience. It is equipped with an Intel Core i7 processor running at 2.8 GHz, providing strong processing power for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and responsive performance along with ample storage capacity. The laptop features a 13.3\\\" NanoEdge display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing. It comes with Intel Iris Xe integrated graphics for smooth graphics performance. Weighing just 1.11 kg, it is incredibly lightweight and highly portable. The laptop features military-grade durability, ensuring durability and reliability. With a two-year warranty and an impressive battery life of up to 11 hours, the ASUS ZenBook 13 offers long-lasting performance and endurance. Priced at 95,000, it provides a premium experience for users seeking a powerful and lightweight laptop.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bd19c0cd-eefd-4bb4-bfba-1f425c9f1826\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Core</th>\n",
              "      <th>CPU Manufacturer</th>\n",
              "      <th>Clock Speed</th>\n",
              "      <th>RAM Size</th>\n",
              "      <th>Storage Type</th>\n",
              "      <th>Display Type</th>\n",
              "      <th>Display Size</th>\n",
              "      <th>Graphics Processor</th>\n",
              "      <th>Screen Resolution</th>\n",
              "      <th>OS</th>\n",
              "      <th>Laptop Weight</th>\n",
              "      <th>Special Features</th>\n",
              "      <th>Warranty</th>\n",
              "      <th>Average Battery Life</th>\n",
              "      <th>Price</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dell</td>\n",
              "      <td>Inspiron</td>\n",
              "      <td>i5</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.4 GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>LCD</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.5 kg</td>\n",
              "      <td>Backlit Keyboard</td>\n",
              "      <td>1 year</td>\n",
              "      <td>6 hours</td>\n",
              "      <td>35,000</td>\n",
              "      <td>The Dell Inspiron is a versatile laptop that c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MSI</td>\n",
              "      <td>GL65</td>\n",
              "      <td>i7</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.6 GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>HDD+SSD</td>\n",
              "      <td>IPS</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>NVIDIA GTX</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.3 kg</td>\n",
              "      <td>RGB Keyboard</td>\n",
              "      <td>2 years</td>\n",
              "      <td>4 hours</td>\n",
              "      <td>55,000</td>\n",
              "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HP</td>\n",
              "      <td>EliteBook</td>\n",
              "      <td>i7</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.8 GHz</td>\n",
              "      <td>16GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>LED</td>\n",
              "      <td>14\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>Windows 11</td>\n",
              "      <td>1.5 kg</td>\n",
              "      <td>Fingerprint Sensor</td>\n",
              "      <td>3 years</td>\n",
              "      <td>8 hours</td>\n",
              "      <td>90,000</td>\n",
              "      <td>The HP EliteBook is a premium laptop designed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lenovo</td>\n",
              "      <td>IdeaPad</td>\n",
              "      <td>i3</td>\n",
              "      <td>Intel</td>\n",
              "      <td>2.1 GHz</td>\n",
              "      <td>8GB</td>\n",
              "      <td>HDD</td>\n",
              "      <td>TN</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>Intel UHD</td>\n",
              "      <td>1366x768</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>2.2 kg</td>\n",
              "      <td>Dolby Audio</td>\n",
              "      <td>1 year</td>\n",
              "      <td>5 hours</td>\n",
              "      <td>25,000</td>\n",
              "      <td>The Lenovo IdeaPad is a versatile laptop that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ASUS</td>\n",
              "      <td>ZenBook Pro</td>\n",
              "      <td>i9</td>\n",
              "      <td>Intel</td>\n",
              "      <td>3.1 GHz</td>\n",
              "      <td>64GB</td>\n",
              "      <td>SSD</td>\n",
              "      <td>OLED</td>\n",
              "      <td>15.6\"</td>\n",
              "      <td>NVIDIA RTX</td>\n",
              "      <td>3840x2160</td>\n",
              "      <td>Windows 10</td>\n",
              "      <td>1.8 kg</td>\n",
              "      <td>NanoEdge Display</td>\n",
              "      <td>2 years</td>\n",
              "      <td>7 hours</td>\n",
              "      <td>200,000</td>\n",
              "      <td>The ASUS ZenBook Pro is a high-end laptop that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd19c0cd-eefd-4bb4-bfba-1f425c9f1826')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd19c0cd-eefd-4bb4-bfba-1f425c9f1826 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd19c0cd-eefd-4bb4-bfba-1f425c9f1826');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a791108-0f12-4249-a2b3-8a3e53b5599c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a791108-0f12-4249-a2b3-8a3e53b5599c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a791108-0f12-4249-a2b3-8a3e53b5599c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Brand   Model Name Core CPU Manufacturer Clock Speed RAM Size Storage Type Display Type  \\\n",
              "0    Dell     Inspiron   i5            Intel     2.4 GHz      8GB          SSD          LCD   \n",
              "1     MSI         GL65   i7            Intel     2.6 GHz     16GB      HDD+SSD          IPS   \n",
              "2      HP    EliteBook   i7            Intel     2.8 GHz     16GB          SSD          LED   \n",
              "3  Lenovo      IdeaPad   i3            Intel     2.1 GHz      8GB          HDD           TN   \n",
              "4    ASUS  ZenBook Pro   i9            Intel     3.1 GHz     64GB          SSD         OLED   \n",
              "\n",
              "  Display Size Graphics Processor Screen Resolution          OS Laptop Weight    Special Features  \\\n",
              "0        15.6\"          Intel UHD         1920x1080  Windows 10        2.5 kg    Backlit Keyboard   \n",
              "1        15.6\"         NVIDIA GTX         1920x1080  Windows 10        2.3 kg        RGB Keyboard   \n",
              "2          14\"          Intel UHD         1920x1080  Windows 11        1.5 kg  Fingerprint Sensor   \n",
              "3        15.6\"          Intel UHD          1366x768  Windows 10        2.2 kg         Dolby Audio   \n",
              "4        15.6\"         NVIDIA RTX         3840x2160  Windows 10        1.8 kg    NanoEdge Display   \n",
              "\n",
              "  Warranty Average Battery Life    Price                                        Description  \n",
              "0   1 year              6 hours   35,000  The Dell Inspiron is a versatile laptop that c...  \n",
              "1  2 years              4 hours   55,000  The MSI GL65 is a high-performance laptop desi...  \n",
              "2  3 years              8 hours   90,000  The HP EliteBook is a premium laptop designed ...  \n",
              "3   1 year              5 hours   25,000  The Lenovo IdeaPad is a versatile laptop that ...  \n",
              "4  2 years              7 hours  200,000  The ASUS ZenBook Pro is a high-end laptop that...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7aada9",
      "metadata": {
        "id": "5e7aada9"
      },
      "source": [
        "### System Design: Stage 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "muGgwBrxxr58",
      "metadata": {
        "id": "muGgwBrxxr58"
      },
      "source": [
        "#### `initialize_conversation()`:\n",
        "This initializes the variable conversation with the system message. Using prompt engineering and chain of thought reasoning, the function will enable the chatbot to keep asking questions until the user requirements have been captured in a dictionary. It also includes Few Shot Prompting(sample conversation between the user and assistant) to align the model about user and assistant responses at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431f76f6",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "431f76f6"
      },
      "outputs": [],
      "source": [
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    example_user_dict = {\n",
        "        'CPU': \"High\",\n",
        "        'GPU': \"Medium\",\n",
        "        'Display Quality':\"High\",\n",
        "        'Portability': \"Low\",\n",
        "        'Multitasking': \"Medium\",\n",
        "        'Budget': \"150000\"\n",
        "    }\n",
        "\n",
        "    example_user_req = {\n",
        "        'CPU': \"_\",\n",
        "        'GPU': \"_\",\n",
        "        'Display Quality': \"_\",\n",
        "        'Portability': \"_\",\n",
        "        'Multitasking': \"_\",\n",
        "        'Budget': \"_\"\n",
        "    }\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\n",
        "    You need to ask relevant questions and understand the user profile by analysing the user's responses.\n",
        "    You final objective is to fill the values for the different keys ('CPU','GPU','Display Quality','Portability','Multitasking','Budget') in the python dictionary and be confident of the values.\n",
        "    These key value pairs define the user's profile.\n",
        "    The python dictionary looks like this\n",
        "    {{'CPU': 'values','GPU': 'values','Display Quality':'values','Portability':'values','Multitasking':'values','Budget':'values'}}\n",
        "\n",
        "    The values for all keys, except 'Budget', should be 'Low', 'Medium', or 'High' based on the importance of the corresponding keys, as stated by user.\n",
        "    All the values in the example dictionary are only representative values.\n",
        "\n",
        "    {delimiter}\n",
        "    Here are some instructions around the values for the different keys. If you do not follow this, you'll be heavily penalised:\n",
        "    - The values for all keys, except 'Budget', should strictly be either 'Low', 'Medium', or 'High' based on the importance of the corresponding keys, as stated by user.\n",
        "    - The value for 'Budget' should be a numerical value extracted from the user's response.\n",
        "    - 'Budget' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range. In case, user does not mention any value for Budget, consider Budget as 300000 which means that the user is okay to spend more\n",
        "    - Do not randomly assign values to any of the keys.\n",
        "    - The values need to be inferred from the user's response.\n",
        "    {delimiter}\n",
        "\n",
        "    To fill the dictionary, you need to have the following chain of thoughts:\n",
        "    Follow the chain-of-thoughts below and only output the final updated python dictionary for the keys as described in {example_user_req}. \\n\n",
        "\n",
        "    {delimiter}\n",
        "\n",
        "    Thought 1: Ask a question to understand the user's profile and requirements. \\n\n",
        "    If their primary use for the laptop is unclear. Ask followup questions to understand their needs.\n",
        "    You are trying to fill the values of all the keys {{'GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget'}} in the python dictionary by understanding the user requirements.\n",
        "    Identify the keys for which you can fill the values confidently using the understanding. \\n\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    If the necessary information has been extracted, only then proceed to the next step. \\n\n",
        "    Otherwise, rephrase the question to capture their profile clearly. \\n\n",
        "\n",
        "    {delimiter}\n",
        "    Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn't in the previous step.\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    Ask questions you might have for all the keys to strengthen your understanding of the user's profile.\n",
        "    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\n",
        "    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\n",
        "    If you are not confident about any of the values, ask clarifying questions.\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here is a sample conversation between the user and assistant:\n",
        "    User: \"Hi, I am an editor.\"\n",
        "    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\"\n",
        "    User: \"I primarily work with After Effects.\"\n",
        "    Assistant: \"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\"\n",
        "    User: \"Yes, sometimes I work with 4K videos as well.\"\n",
        "    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\"\n",
        "    User: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
        "    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"\n",
        "    User: \"my max budget is 1.5lakh inr\"\n",
        "    Assistant: \"{example_user_dict}\"\n",
        "    {delimiter}\n",
        "\n",
        "    Start with a short welcome message and encourage the user to share their requirements as precisely and accurate as possible so that you can make decision appropriately.\n",
        "    \"\"\"\n",
        "    conversation = [\n",
        "        {\"role\": \"system\", \"content\": system_message}\n",
        "    ]\n",
        "    return conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae92d8e0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ae92d8e0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "debug_conversation = initialize_conversation()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ucpdMHI5_jEX",
      "metadata": {
        "id": "ucpdMHI5_jEX"
      },
      "source": [
        "#### `get_chat_completions()`:\n",
        "\n",
        "This function perform LLM call using the Chat Completions API to get the LLM response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYShGKumNEIM",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dYShGKumNEIM"
      },
      "outputs": [],
      "source": [
        "# Define a Chat Completions API call\n",
        "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions(input, json_format=False):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    # JSON Output\n",
        "    if json_format == True:\n",
        "        system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
        "        # Append the input prompt to include JSON response as specified by OpenAI\n",
        "        input[0]['content'] += system_message_json_output\n",
        "\n",
        "        # JSON return type specified\n",
        "        chat_completion_json = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            response_format = {\"type\": \"json_object\"},\n",
        "            seed = 1234\n",
        "        )\n",
        "        output = json.loads(chat_completion_json.choices[0].message.content)\n",
        "\n",
        "    # Non-JSON Output\n",
        "    else:\n",
        "        chat_completion = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            seed = 2345\n",
        "        )\n",
        "        output = chat_completion.choices[0].message.content\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I6gq3hIj6XEr",
      "metadata": {
        "id": "I6gq3hIj6XEr"
      },
      "source": [
        "#### iterate_response() - Helper Function:\n",
        "We've created a small helper test function to ensure the model's response is consistent.\n",
        "Uncomment the code blocks and run the function `iterate_response(response)` to check if the response of the `intent_confirmation_layer`is consistent.}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c369bd0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3c369bd0"
      },
      "outputs": [],
      "source": [
        "def iterate_llm_response(funct, debug_response, num=10):\n",
        "    \"\"\"\n",
        "    Calls a specified function repeatedly and prints the results.\n",
        "    This function is designed to test the consistency of a response from a given function.\n",
        "    It calls the function multiple times (default is 10) and prints out the iteration count,\n",
        "    the function's response(s).\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        funct : function\n",
        "        The function to be tested. This function should accept a single argument and return the response value(s)\n",
        "\n",
        "        debug_response : dict\n",
        "        The input argument to be passed to 'funct' on each call.\n",
        "\n",
        "        num : int\n",
        "        The number of times 'funct' will be called. Defaults to 10.\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range (1, num+1):\n",
        "        print(f\"Iteration: {i}\")\n",
        "        response = funct(debug_response)\n",
        "        print(response)\n",
        "        print('#' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5613d86-c6b8-4c03-9ddf-ec6c3bd03803",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a5613d86-c6b8-4c03-9ddf-ec6c3bd03803"
      },
      "outputs": [],
      "source": [
        "# iterate_llm_response(get_chat_completions, messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fca12a4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fca12a4"
      },
      "outputs": [],
      "source": [
        "debug_user_input = \"Hi, I am Purushothama. I need a laptop for for designing high end 3D Graphics.\"\n",
        "debug_conversation.append({\"role\": \"user\", \"content\": debug_user_input})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1vip-2uj_M7",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1vip-2uj_M7",
        "outputId": "abbfc756-7836-49d3-e0ad-1a54cf1870bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, I am Purushothama. I need a laptop for for designing high end 3D Graphics.\n"
          ]
        }
      ],
      "source": [
        "print(debug_conversation[1][\"content\"]) # User Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd0a9ed",
      "metadata": {
        "id": "fdd0a9ed",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Getting the response from the Assistant by passing the conversation to the Chat Completions API\n",
        "debug_response_assistant = get_chat_completions(debug_conversation)\n",
        "display(debug_response_assistant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kN2nZh_dkT2v",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kN2nZh_dkT2v"
      },
      "outputs": [],
      "source": [
        "debug_conversation.append(({\"role\": \"system\", \"content\": debug_response_assistant}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389ae50b",
      "metadata": {
        "id": "389ae50b"
      },
      "source": [
        "Typically, whenever the chatbot is interacting with the user, all the conversations should be moderated to identify any inappropriate content. Let's look at the function that can help with it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc13511",
      "metadata": {
        "id": "5cc13511"
      },
      "source": [
        "#### `moderation_check()`:\n",
        "This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, you can add a break statement to end the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c799b4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e5c799b4"
      },
      "outputs": [],
      "source": [
        "def moderation_check(user_input):\n",
        "    \"\"\"\n",
        "    This function will call OpenAI API to perform moderation check on the user's input.\n",
        "    Any value below or equal to `user_value` passed as argument is marked as 1 else 0\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        user_input : str\n",
        "        Any input which is provided by user for querying OpenAI API\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        status : bool\n",
        "        Returns True, if any violation is observed, else False\n",
        "\n",
        "    \"\"\"\n",
        "    response = openai.moderations.create(input=user_input)\n",
        "    moderation_output = response.results[0].flagged\n",
        "    if response.results[0].flagged == True:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d12659",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "86d12659"
      },
      "outputs": [],
      "source": [
        "moderation_check(debug_user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e289d1c1",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e289d1c1",
        "outputId": "a3f2f08a-68c9-471b-e6e8-ddff0b875096"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'moderation_check' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1536804239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmoderation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_response_assistant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'moderation_check' is not defined"
          ]
        }
      ],
      "source": [
        "moderation_check(debug_response_assistant)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "543bca28",
      "metadata": {
        "id": "543bca28"
      },
      "source": [
        "#### `intent_confirmation_layer()`:\n",
        "\n",
        "This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly.\n",
        "\n",
        "Understanding the user's profile, essentially means that all the features: CPU Intensity, GPU intensity, Display quality, Portability, Multitasking, Budget are captured or not. Let's look at the function that helps us verify that.\n",
        "\n",
        "Specifically, this checks if the following properties for the user has been captured or not\n",
        "   - CPU\n",
        "   - GPU\n",
        "   - Display Quality\n",
        "   - Portability\n",
        "   - Multitasking\n",
        "   - Budget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w1o5KuBeONhF",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w1o5KuBeONhF"
      },
      "outputs": [],
      "source": [
        "def intent_confirmation_layer(response_assistant):\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    allowed_values = {'Low','Medium','High'}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a senior evaluator who has an eye for detail.The input text will contain a user requirement captured through 6 keys.\n",
        "    You are provided an input. You need to evaluate if the input text has the following keys:\n",
        "    {{\n",
        "    'CPU':'values',\n",
        "    'GPU':'values',\n",
        "    'Display Quality':'values',\n",
        "    'Portability':'values',\n",
        "    'Multitasking':'values',\n",
        "    'Budget':'number'\n",
        "    }}\n",
        "    The values for the keys should only be from the allowed values: {allowed_values}. Except, 'Budget' key can take only a numerical value which can be in string representation as well.\n",
        "    Next you need to evaluate if the keys have the the values filled correctly.\n",
        "    Only output a one-word string in JSON format at the key 'result' - Yes/No.\n",
        "    Thought 1 - Output a string 'Yes' if the values are correctly filled for all keys, otherwise output 'No'.\n",
        "    Thought 2 - If the answer is No, mention the reason in the key 'reason'.\n",
        "    Thought 3 - Think carefully before the answering.\n",
        "    \"\"\"\n",
        "\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\":prompt },\n",
        "        {\"role\": \"user\", \"content\":f\"\"\"Here is the input: {response_assistant}\"\"\" }\n",
        "    ]\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = messages,\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        seed = 1234\n",
        "    )\n",
        "\n",
        "    json_output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "    return json_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TbsoK64ZXnDZ",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "TbsoK64ZXnDZ",
        "outputId": "ddaeece4-7d1e-4939-8797-b358bacd76df"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'debug_response_assistant' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2228858698.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdebug_response_assistant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'debug_response_assistant' is not defined"
          ]
        }
      ],
      "source": [
        "debug_response_assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89031a63",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "89031a63",
        "outputId": "625a1616-15a8-4178-eeff-b005c361ebda"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'debug_response_assistant' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-555901426.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdebug_confirmation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent_confirmation_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_response_assistant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_confirmation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'debug_response_assistant' is not defined"
          ]
        }
      ],
      "source": [
        "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
        "display(debug_confirmation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8941aef4",
      "metadata": {
        "id": "8941aef4"
      },
      "source": [
        "#### `dictionary_present()`:\n",
        "\n",
        "This function checks if the final understanding of user's profile is returned by the chatbot is a Python dictionary or not.\n",
        "This is important as it'll be used later on for finding the right laptops using dictionary matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KjZlut6U2p_e",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KjZlut6U2p_e"
      },
      "outputs": [],
      "source": [
        "def dictionary_present(response):\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    user_req = {\n",
        "        'CPU': \"High\",\n",
        "        'GPU': \"Medium\",\n",
        "        'Display Quality':\"High\",\n",
        "        'Portability': \"Low\",\n",
        "        'Multitasking': \"Medium\",\n",
        "        'Budget': 150000\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"You are a python expert. You are provided an input.\n",
        "    You have to check if there is a python dictionary present in the string.\n",
        "    It will have the following format {user_req}.\n",
        "    Your task is to just extract the relevant values from the input and return only the python dictionary in JSON format.\n",
        "    The output should match the format as {user_req}.\n",
        "\n",
        "    {delimiter}\n",
        "    Make sure that the value of budget is also present in the user input. ###\n",
        "    The output should contain the exact keys and values as present in the input.\n",
        "    Ensure the keys and values are in the given format:\n",
        "    {{\n",
        "    'CPU': 'Low/Medium/High'\n",
        "    'GPU': 'Low/Medium/High',\n",
        "    'Display Quality':'Low/Medium/High',\n",
        "    'Portability':'Low/Medium/High',\n",
        "    'Multitasking':'Low/Medium/High',\n",
        "    'Processing speed':'Low/Medium/High',\n",
        "    'Budget':'Numerical Value without any comma'\n",
        "    }}\n",
        "    Here are some sample input output pairs for better understanding:\n",
        "    {delimiter}\n",
        "    input 1: CPU: Low - GPU: Low - Display Quality: High - Portability: Low - Multitasking: High - Budget: 50000\n",
        "    output 1: {{'CPU':'Low', GPU': 'Low', 'Display Quality': 'High', 'Portability': 'Low', 'Multitasking': 'High', 'Budget': 50000}}\n",
        "\n",
        "    input 2: CPU: Low - GPU: High - Display Quality: High - Portability: Medium - Multitasking: High - Budget: 90000\n",
        "    output 2: {{'CPU':'Low', GPU': 'High', 'Display Quality': 'High', 'Portability': 'Medium', 'Multitasking': 'High', 'Budget': 90000}}\n",
        "\n",
        "    input 2: CPU: High - GPU: High - Display Quality: High - Portability: Low - Multitasking: High - Budget: 125000\n",
        "    output 2: {{'CPU':'High', GPU': 'High', 'Display Quality': 'High', 'Portability': 'Low', 'Multitasking': 'High', 'Budget': 125000}}\n",
        "    {delimiter}\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\":prompt },\n",
        "        {\"role\": \"user\", \"content\":f\"\"\"Here is the user input: {response}\"\"\" }\n",
        "    ]\n",
        "    confirmation = get_chat_completions(messages, json_format = True)\n",
        "    return confirmation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01dd4ca1",
      "metadata": {
        "id": "01dd4ca1"
      },
      "source": [
        "Let's start by passing the `debug_response_assistant`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qhG-yoxqZ6g2",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qhG-yoxqZ6g2",
        "outputId": "cce05f7b-7218-44cf-e0b8-5b81dd80c7ac"
      },
      "outputs": [
        {
          "ename": "RetryError",
          "evalue": "RetryError[<Future at 0x7c35805115e0 state=finished raised RateLimitError>]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4204482734.py\u001b[0m in \u001b[0;36mget_chat_completions\u001b[0;34m(input, json_format)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# JSON return type specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         chat_completion_json = openai.chat.completions.create(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1123466534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresponse_dict_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_debug_response_assistant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mresponse_dict_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1598766022.py\u001b[0m in \u001b[0;36mdictionary_present\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34mf\"\"\"Here is the user input: {response}\"\"\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     ]\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mconfirmation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_chat_completions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfirmation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7c35805115e0 state=finished raised RateLimitError>]"
          ]
        }
      ],
      "source": [
        "sample_debug_response_assistant = \"\"\"\n",
        "{\n",
        " 'CPU': 'Low',\n",
        " 'GPU':'High',\n",
        " 'Display Quality':'High',\n",
        " 'Portability':'Low',\n",
        " 'Multitasking':'Low',\n",
        " 'Budget':'50,000 INR'\n",
        "}\n",
        "\"\"\"\n",
        "response_dict_n = dictionary_present(sample_debug_response_assistant)\n",
        "response_dict_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Jwp8q2NGGAg",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Jwp8q2NGGAg"
      },
      "outputs": [],
      "source": [
        "type(response_dict_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TWY1b2OXRx4u",
      "metadata": {
        "id": "TWY1b2OXRx4u"
      },
      "source": [
        "## System Design: Stage 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed43b69-e250-49ad-b5bb-a6098cec0c4b",
      "metadata": {
        "id": "1ed43b69-e250-49ad-b5bb-a6098cec0c4b"
      },
      "source": [
        "#### `product_map_layer()`:\n",
        "This function will analyze the `laptop_description` and create a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16152886-2ecd-463d-a163-1147d60b873c",
      "metadata": {
        "id": "16152886-2ecd-463d-a163-1147d60b873c"
      },
      "outputs": [],
      "source": [
        "def product_map_layer(laptop_description):\n",
        "    \"\"\"\n",
        "    This function will analyze the `laptop_description` and create a dictionary\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        laptop_description : str\n",
        "        Brief description about the laptop\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        response : dict\n",
        "        Return a dictioanry consisting of all key value pairs\n",
        "\n",
        "    \"\"\"\n",
        "    delimiter = \"#####\"\n",
        "\n",
        "    lap_spec = {\n",
        "        \"CPU\": \"(CPU Performance)\",\n",
        "        \"GPU\": \"(GPU Performance)\",\n",
        "        \"Display Quality\": \"(Resolution of Display)\",\n",
        "        \"Portability\": \"(Laptop Weight)\",\n",
        "        \"Multitasking\": \"(RAM Size)\",\n",
        "        \"Budget\": \"(Price of laptop)\"\n",
        "    }\n",
        "\n",
        "    values = {'Low', 'Medium', 'High'}\n",
        "\n",
        "    prompt=f\"\"\"\n",
        "    You are a intelligent laptop buying assitant who is an expert in extracting features of a laptop from the provided laptop description data\n",
        "    To extract features from laptop description, it is must to adhere to following steps:\n",
        "\n",
        "    Step 1: Extract the laptop's primary features from the description as follows: {laptop_description}\n",
        "    Step 2: Store the extracted features in {lap_spec} \\\n",
        "    Step 3: Classify each of the items in {lap_spec} into {values} based on the following rules: \\\n",
        "\n",
        "    {delimiter}\n",
        "    GPU:\n",
        "    - Low: <<< if GPU is an entry-level such as an integrated graphics processor or entry-level dedicated graphics like Intel UHD >>> , \\n\n",
        "    - Medium: <<< if mid-range dedicated graphics like M1, AMD Radeon, Intel Iris >>> , \\n\n",
        "    - High: <<< high-end dedicated graphics like Nvidia RTX or NVIDIA GTX series >>> , \\n\n",
        "\n",
        "    CPU:\n",
        "    - Low: <<< if CPU is an entry-level processor like AMD Athlon, Intel Celeron, Intel Core 2 Duo >>> , \\n\n",
        "    - Medium: <<< if mid-range processor like Intel Core i3, Intel Core i5, AMD Ryzen 3 or AMD Ryzen 5 >>> , \\n\n",
        "    - High: <<< if a high-end processor like Intel Core i7, Intel Core i9, AMD Ryzen 7, AMD Ryzen 9 or Apple Series of Processors>>> , \\n\n",
        "\n",
        "    Display Quality:\n",
        "    - Low: <<< if resolution is below Full HD (e.g., 1366x768). >>> , \\n\n",
        "    - Medium: <<< if Full HD resolution (1920x1080) or higher. >>> , \\n\n",
        "    - High: <<< if High-resolution display (e.g., 4K, Retina) with excellent color accuracy and features like HDR support. >>> \\n\n",
        "\n",
        "    Portability:\n",
        "    - High: <<< if laptop weight is less than or equal to 1.0 kg >>> , \\n\n",
        "    - Medium: <<< if laptop weight is between 1.0 kg and 2.0 kg >>> , \\n\n",
        "    - Low: <<< if laptop weight is greater than or equal to 2.0 kg >>> \\n\n",
        "    Classifying laptops on the basis of portability has to adhere with mentioned rules and are to be be done followed very strictly\n",
        "\n",
        "    Multitasking:\n",
        "    - Low: <<< If RAM size is less than or equal to 8 GB >>> , \\n\n",
        "    - Medium: <<< if RAM size is between 9 GB & 16 GB >>> , \\n\n",
        "    - High: <<< if RAM size is greater than 20 GB >>> \\n\n",
        "\n",
        "    Budget:\n",
        "    Extract the price of the laptop which is mentioned in Indian Rupee and convert the same into proper integer format so that it can be analyzed further.\n",
        "    Be very careful while extracting price of the product. In case, if you are unable to extract the price mention the price as 0\n",
        "\n",
        "\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here is input output pair for few-shot learning:\n",
        "    input 1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
        "    output 1: {{'CPU': 'Medium', 'GPU':'Medium', 'Display Quality': 'Medium', 'Portability':'Low', 'Multitasking':'Low', 'Budget': 35000}}\n",
        "\n",
        "    {delimiter}\n",
        "    ### Strictly don't keep any other text in the values of the JSON dictionary other than Low, Medium or High else will be heavily penalized###\n",
        "    \"\"\"\n",
        "    input = f\"\"\"Follow the above instructions step-by-step and output the dictionary in JSON format {lap_spec} for the following laptop {laptop_description}.\"\"\"\n",
        "    #see that we are using the Completion endpoint and not the Chatcompletion endpoint\n",
        "    messages=[{\"role\": \"system\", \"content\":prompt },{\"role\": \"user\",\"content\":input}]\n",
        "\n",
        "    response = get_chat_completions(messages, json_format = True)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e409894-0c19-49e7-9a77-986e18e38b5e",
      "metadata": {
        "id": "3e409894-0c19-49e7-9a77-986e18e38b5e"
      },
      "outputs": [],
      "source": [
        "def filter_data_by_budget(max_budget_value=None):\n",
        "    \"\"\"\n",
        "    This function will filter only those rows which has a budget lesser than the argument `max_budget_value` passed\n",
        "    If no budget value is passed as argument, it means all rows are selected\n",
        "    If the budget is selected such that after filtering no rows are present; then `False` is returned\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        max_budget_value : int\n",
        "        This is the maximum budget selected\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        temp_df : obj\n",
        "        Returns pandas dataframe object with only those rows which has budget less than equal to `max_budget_value`\n",
        "\n",
        "    \"\"\"\n",
        "    # pattern = r\"(\\d*)\"\n",
        "    # max_budget_value = int(re.search(pattern, max_budget_value.replace(\",\", \"\")).group())\n",
        "\n",
        "    temp_df = df[df[\"Budget\"] <= max_budget_value]\n",
        "    if len(temp_df) == 0:\n",
        "        return False\n",
        "    else:\n",
        "        return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8688342d-a456-4062-8eeb-9de8d1f786e3",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8688342d-a456-4062-8eeb-9de8d1f786e3"
      },
      "outputs": [],
      "source": [
        "def higher_the_better_rule(series, user_value):\n",
        "    \"\"\"\n",
        "    This function will change specific dataframe column values as mentioned in argument `series`\n",
        "    Any value above or equal to `user_value` passed as argument is marked as 1 else 0\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        series : obj\n",
        "        Each column of pandas dataframe is passed as series\n",
        "\n",
        "        user_value : str\n",
        "        User value extracted from user for the particlular feature\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        series : obj\n",
        "        Return pandas series for that particular column\n",
        "\n",
        "    \"\"\"\n",
        "    if user_value == \"High\":\n",
        "        series_ = series.map({\"High\": 1.0, \"Medium\": 0.0, \"Low\": 0.0})\n",
        "    elif user_value == \"Medium\":\n",
        "        series_ = series.map({\"High\": 1.2, \"Medium\": 1, \"Low\": 0})\n",
        "    elif user_value == \"Low\":\n",
        "        series_ = series.map({\"High\": 1.5, \"Medium\": 1.2, \"Low\": 1})\n",
        "    else:\n",
        "        return False  #Inavlid user value\n",
        "\n",
        "    return series_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1ef887-dcc8-44e7-af23-29d9e25fc9c5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5e1ef887-dcc8-44e7-af23-29d9e25fc9c5"
      },
      "outputs": [],
      "source": [
        "def lower_the_better_rule(series, user_value):\n",
        "    \"\"\"\n",
        "    This function will change specific dataframe column values as mentioned in argument `column_name`\n",
        "    Any value below or equal to `user_value` passed as argument is marked as 1 else 0\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        series : obj\n",
        "        Each column of pandas dataframe is passed as series\n",
        "\n",
        "        user_value : str\n",
        "        User value extracted from user for the particlular feature\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        series : obj\n",
        "        Return pandas series for that particular column\n",
        "\n",
        "    \"\"\"\n",
        "    if user_value == \"High\":\n",
        "        series_ = series.map({\"High\": 1, \"Medium\": 1.2, \"Low\": 1.5})\n",
        "    elif user_value == \"Medium\":\n",
        "        series_ = series.map({\"High\": 0, \"Medium\": 1, \"Low\": 1.2})\n",
        "    elif user_value == \"Low\":\n",
        "        series_ = series.map({\"High\": 0, \"Medium\": 0, \"Low\": 1})\n",
        "    else:\n",
        "        return False  #Inavlid user value\n",
        "\n",
        "    return series_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e9ab9a-5eca-4956-9ba2-93d872939670",
      "metadata": {
        "id": "53e9ab9a-5eca-4956-9ba2-93d872939670",
        "outputId": "7ce7b360-69c1-41fa-b7a2-0214a0748cea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Dell Inspiron is a versatile laptop that c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The HP EliteBook is a premium laptop designed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Lenovo IdeaPad is a versatile laptop that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The ASUS ZenBook Pro is a high-end laptop that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description\n",
              "0  The Dell Inspiron is a versatile laptop that c...\n",
              "1  The MSI GL65 is a high-performance laptop desi...\n",
              "2  The HP EliteBook is a premium laptop designed ...\n",
              "3  The Lenovo IdeaPad is a versatile laptop that ...\n",
              "4  The ASUS ZenBook Pro is a high-end laptop that..."
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(df[\"Description\"], columns=[\"Description\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7ee2e3-9e48-47f0-bbab-85ec43fac565",
      "metadata": {
        "id": "dd7ee2e3-9e48-47f0-bbab-85ec43fac565",
        "outputId": "86aa7e1b-6143-4cec-bd31-e1c9ee47340c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>CPU</th>\n",
              "      <th>GPU</th>\n",
              "      <th>Display Quality</th>\n",
              "      <th>Portability</th>\n",
              "      <th>Multitasking</th>\n",
              "      <th>Budget</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Dell Inspiron is a versatile laptop that c...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>35000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>55000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The HP EliteBook is a premium laptop designed ...</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>90000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Lenovo IdeaPad is a versatile laptop that ...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Low</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The ASUS ZenBook Pro is a high-end laptop that...</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description     CPU   GPU Display Quality Portability  \\\n",
              "0  The Dell Inspiron is a versatile laptop that c...  Medium   Low          Medium         Low   \n",
              "1  The MSI GL65 is a high-performance laptop desi...    High  High          Medium      Medium   \n",
              "2  The HP EliteBook is a premium laptop designed ...    High   Low          Medium        High   \n",
              "3  The Lenovo IdeaPad is a versatile laptop that ...  Medium   Low             Low      Medium   \n",
              "4  The ASUS ZenBook Pro is a high-end laptop that...    High  High            High        High   \n",
              "\n",
              "  Multitasking  Budget  \n",
              "0          Low   35000  \n",
              "1         High   55000  \n",
              "2         High   90000  \n",
              "3          Low   25000  \n",
              "4         High  200000  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"dict_\"] = df[\"Description\"].apply(product_map_layer)\n",
        "df = pd.concat([df, df[\"dict_\"].apply(pd.Series)], axis=1)\n",
        "if \"dict_\" in df.columns:\n",
        "    df = df.drop(columns=['dict_'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc7197e3-c6cc-41cc-b3d5-ba356ca23ec5",
      "metadata": {
        "id": "dc7197e3-c6cc-41cc-b3d5-ba356ca23ec5"
      },
      "outputs": [],
      "source": [
        "sample_user_query = {\n",
        "    'CPU': 'Medium',\n",
        "    'GPU': 'High',\n",
        "    'Display Quality': 'Low',\n",
        "    'Portability': 'High',\n",
        "    'Multitasking': 'Medium',\n",
        "    'Budget': 80000\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a798fb9f-f69f-4d78-8c76-25d12233857a",
      "metadata": {
        "id": "a798fb9f-f69f-4d78-8c76-25d12233857a",
        "outputId": "4e2e7a77-00ef-4738-ffbe-7f6893712a10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>CPU</th>\n",
              "      <th>GPU</th>\n",
              "      <th>Display Quality</th>\n",
              "      <th>Portability</th>\n",
              "      <th>Multitasking</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Acer Predator is a powerhouse laptop desig...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.2</td>\n",
              "      <td>80000</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Lenovo ThinkPad is a powerful laptop desig...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>60000</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The MSI GL65 is a high-performance laptop desi...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>55000</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description  CPU  GPU  Display Quality  Portability  \\\n",
              "0  The Acer Predator is a powerhouse laptop desig...  1.2  1.0              1.2          1.5   \n",
              "1  The Lenovo ThinkPad is a powerful laptop desig...  1.2  1.0              1.5          1.0   \n",
              "2  The MSI GL65 is a high-performance laptop desi...  1.2  1.0              1.2          1.2   \n",
              "\n",
              "   Multitasking  Budget  Score  \n",
              "0           1.2   80000    6.1  \n",
              "1           1.2   60000    5.9  \n",
              "2           1.2   55000    5.8  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_after_budget_filter = filter_data_by_budget(sample_user_query[\"Budget\"])\n",
        "\n",
        "df_after_budget_filter[\"CPU\"] = higher_the_better_rule(df_after_budget_filter[\"CPU\"], sample_user_query[\"CPU\"])\n",
        "df_after_budget_filter[\"GPU\"] = higher_the_better_rule(df_after_budget_filter[\"GPU\"], sample_user_query[\"GPU\"])\n",
        "df_after_budget_filter[\"Display Quality\"] = higher_the_better_rule(df_after_budget_filter[\"Display Quality\"], sample_user_query[\"Display Quality\"])\n",
        "df_after_budget_filter[\"Portability\"] = lower_the_better_rule(df_after_budget_filter[\"Portability\"], sample_user_query[\"Portability\"])\n",
        "df_after_budget_filter[\"Multitasking\"] = higher_the_better_rule(df_after_budget_filter[\"Multitasking\"], sample_user_query[\"Multitasking\"])\n",
        "df_after_budget_filter[\"Score\"] = df_after_budget_filter[\"CPU\"] + df_after_budget_filter[\"GPU\"] + df_after_budget_filter[\"Display Quality\"] + df_after_budget_filter[\"Portability\"] + df_after_budget_filter[\"Multitasking\"]\n",
        "\n",
        "df_after_budget_filter = df_after_budget_filter.sort_values(by=[\"Score\", \"Budget\"], ascending=[False, True], ignore_index=True)\n",
        "df_after_budget_filter.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kRBzXIcrea7Y",
      "metadata": {
        "id": "kRBzXIcrea7Y"
      },
      "source": [
        "## System Design: Stage 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a0dd52-7780-400e-87b5-e65a0f34cfc3",
      "metadata": {
        "id": "92a0dd52-7780-400e-87b5-e65a0f34cfc3"
      },
      "source": [
        "#### `initialize_conv_reco()`:\n",
        "This function will act as a salesman which would interact with user in an engaging manner such that user should be able to understand all the shortlisted laptops which were provided by earler stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6270ac40",
      "metadata": {
        "id": "6270ac40"
      },
      "outputs": [],
      "source": [
        "def initialize_conv_reco(products):\n",
        "    system_message = f\"\"\"\n",
        "    You are a good laptop salesman representative who is an expert in understanding user requirement in terms of buying a laptop as per user requirement\n",
        "    Top recommended laptops have already been shortlisted and provided\n",
        "    You need to explain specifications of those laptops with utmost accuracy and also make sure to keep user requirement in check while explaining those laptops\n",
        "\n",
        "    Start with a brief summary of each laptop in the following format:\n",
        "    1. <Laptop Name> : <Price in Indian Rupees>, <Major specifications of the laptop>\n",
        "    2. <Laptop Name> : <Price in Rupees>, <Major specifications of the laptop>\n",
        "\n",
        "    \"\"\"\n",
        "    user_message = f\"\"\" These are the user's products: {products}\"\"\"\n",
        "    conversation = [\n",
        "        {\"role\": \"system\", \"content\": system_message },\n",
        "        {\"role\":\"user\",\"content\":user_message}\n",
        "    ]\n",
        "    return conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a66294",
      "metadata": {
        "id": "e0a66294"
      },
      "source": [
        "Let's initialize the conversation for recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd95e8c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd95e8c5",
        "outputId": "e5314399-65c0-4772-d683-ce496e410ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Acer Predator : 80,000 INR, Intel Core i7 processor (2.8 GHz), 16GB RAM, SSD storage, 17.3\" IPS display (1920x1080 resolution), NVIDIA GTX graphics card, 3.2 kg weight, dual cooling fans, 5 hours battery life, one-year warranty. Ideal for gamers looking for powerful gaming performance and portability.\n",
            "\n",
            "2. Lenovo ThinkPad : 60,000 INR, AMD Ryzen 7 processor (3.0 GHz), 16GB RAM, SSD storage, 14\" IPS display (2560x1440 resolution), NVIDIA GTX graphics card, 1.6 kg weight, backlit keyboard, 6 hours battery life, three-year warranty. Suitable for professionals seeking powerful performance and a versatile display.\n",
            "\n",
            "3. MSI GL65 : 55,000 INR, Intel Core i7 processor (2.6 GHz), 16GB RAM, HDD and SSD storage, 15.6\" IPS display (1920x1080 resolution), NVIDIA GTX graphics card, 2.3 kg weight, RGB keyboard, 4 hours battery life, two-year warranty. Great choice for gamers looking for high performance and portability.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "debug_conversation_reco = initialize_conv_reco(list(df_after_budget_filter.head(3)[\"Description\"].values))\n",
        "debug_recommendation = get_chat_completions(debug_conversation_reco)\n",
        "print(debug_recommendation + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8885e9fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "8885e9fc",
        "outputId": "ce53a9ec-a4c9-44ca-cb82-deb521614158"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nThe ideal laptop for travel among the provided options would be the **Lenovo ThinkPad**. Here are the details:\\n\\n1. **Lenovo ThinkPad** : 60,000 Rupees, Ryzen 7 processor from AMD clocked at 3.0 GHz, 16GB of RAM, SSD storage, 14\" IPS display with 2560x1440 resolution, NVIDIA GTX graphics card, lightweight at 1.6 kg, backlit keyboard, three-year warranty, battery life up to 6 hours.\\n\\nThe Lenovo ThinkPad is lightweight at just 1.6 kg, making it highly portable and ideal for travel. It offers a good balance between performance and portability, making it convenient to carry around during your travels. It also has a decent battery life of up to 6 hours, allowing you to work or enjoy entertainment on the go without constantly needing to recharge.\\n\\nIf you prioritize portability and a longer battery life for your travel needs, the Lenovo ThinkPad would be the suitable choice.\\n'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "debug_user_input = \"Which is ideal for travel?\"\n",
        "\n",
        "debug_conversation_reco.append({\"role\": \"user\", \"content\": debug_user_input})\n",
        "debug_response_asst_reco = get_chat_completions(debug_conversation_reco)\n",
        "display('\\n' + debug_response_asst_reco + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Djt_gMeaeo-F",
      "metadata": {
        "id": "Djt_gMeaeo-F"
      },
      "source": [
        "## Unified System\n",
        "\n",
        "In this layer, we combine all the three stages that we defined above.\n",
        "\n",
        "`Stage 1` + `Stage 2` + `Stage 3`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8156fc35",
      "metadata": {
        "id": "8156fc35"
      },
      "source": [
        "Bringing everything together, we create a `diagloue_mgmt_system()` function that contains the logic of how the different layers would interact with each other. This will be the function that we'll call to initiate the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4oHQZqsUmre",
      "metadata": {
        "id": "K4oHQZqsUmre"
      },
      "outputs": [],
      "source": [
        "def dialogue_mgmt_system():\n",
        "    conversation = initialize_conversation()\n",
        "    introduction = get_chat_completions(conversation)\n",
        "    display(introduction + '\\n')\n",
        "    top_3_laptops = None\n",
        "    user_input = ''\n",
        "    while(user_input != \"exit\"):\n",
        "        user_input = input(\"\")\n",
        "\n",
        "        moderation = moderation_check(user_input)\n",
        "        if moderation == 'Flagged':\n",
        "            display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "            break\n",
        "\n",
        "        if top_3_laptops is None:\n",
        "            conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "            response_assistant = get_chat_completions(conversation)\n",
        "            moderation = moderation_check(response_assistant)\n",
        "            if moderation == 'Flagged':\n",
        "                display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                break\n",
        "\n",
        "            confirmation = intent_confirmation_layer(response_assistant)\n",
        "            if \"No\" in confirmation.get('result'):\n",
        "                conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "                print(\"\\n\" + str(response_assistant) + \"\\n\")\n",
        "\n",
        "            else:\n",
        "                response = dictionary_present(response_assistant)\n",
        "\n",
        "                # print(\"Thank you for providing all the information. Kindly wait, while I fetch the products: \\n\")\n",
        "                # top_3_laptops = compare_laptops_with_user(response)\n",
        "                # print(\"Top 3 laptops are\", top_3_laptops)\n",
        "                # validated_reco = recommendation_validation(top_3_laptops)\n",
        "\n",
        "                df_after_budget_filter = filter_data_by_budget(response[\"Budget\"])\n",
        "\n",
        "                df_after_budget_filter[\"CPU\"] = higher_the_better_rule(df_after_budget_filter[\"CPU\"], response[\"CPU\"])\n",
        "                df_after_budget_filter[\"GPU\"] = higher_the_better_rule(df_after_budget_filter[\"GPU\"], response[\"GPU\"])\n",
        "                df_after_budget_filter[\"Display Quality\"] = higher_the_better_rule(df_after_budget_filter[\"Display Quality\"], response[\"Display Quality\"])\n",
        "                df_after_budget_filter[\"Portability\"] = lower_the_better_rule(df_after_budget_filter[\"Portability\"], response[\"Portability\"])\n",
        "                df_after_budget_filter[\"Multitasking\"] = higher_the_better_rule(df_after_budget_filter[\"Multitasking\"], response[\"Multitasking\"])\n",
        "                df_after_budget_filter[\"Score\"] = df_after_budget_filter[\"CPU\"] + df_after_budget_filter[\"GPU\"] + df_after_budget_filter[\"Display Quality\"] + df_after_budget_filter[\"Portability\"] + df_after_budget_filter[\"Multitasking\"]\n",
        "\n",
        "                df_after_budget_filter = df_after_budget_filter.sort_values(by=[\"Score\", \"Budget\"], ascending=[False, True], ignore_index=True)\n",
        "\n",
        "\n",
        "                conversation_reco = initialize_conv_reco(list(df_after_budget_filter.head(3)[\"Description\"].values))\n",
        "                conversation_reco.append({\"role\": \"user\", \"content\": \"This is my user profile\" + str(response)})\n",
        "                recommendation = get_chat_completions(conversation_reco)\n",
        "                moderation = moderation_check(recommendation)\n",
        "                if moderation == 'Flagged':\n",
        "                    display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                    break\n",
        "                conversation_reco.append({\"role\": \"assistant\", \"content\": str(recommendation)})\n",
        "                print(str(recommendation) + '\\n')\n",
        "        else:\n",
        "            conversation_reco.append({\"role\": \"user\", \"content\": user_input})\n",
        "            response_asst_reco = get_chat_completions(conversation_reco)\n",
        "            moderation = moderation_check(response_asst_reco)\n",
        "            if moderation == 'Flagged':\n",
        "                print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "                break\n",
        "            print('\\n' + response_asst_reco + '\\n')\n",
        "            conversation.append({\"role\": \"assistant\", \"content\": response_asst_reco})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KI9EWNc16xxe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "KI9EWNc16xxe",
        "outputId": "44e80d0d-4806-4707-fa68-9c41914bafc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Welcome! I'm here to assist you in finding the best laptop based on your requirements. Please share your specific needs and preferences so that I can help you make an informed decision. Let's start by understanding your primary use for the laptop and any specific features you are looking for.\\n\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " I am looking for a good laptop for graphics rendering activity under 1.5 Lakh\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Great! As someone who is involved in graphics rendering activities, you would need a laptop with high processing power and a good GPU. To ensure I understand your requirements clearly, could you please let me know if you primarily work with high-resolution graphics and animations during your rendering activities?\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " I would need a high resolution display with good multitasking capability\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Thank you for providing that information. For graphics rendering activities that involve high-resolution work, a high-quality display is essential for accurate color representation and detail. Multitasking capability is also important to handle multiple rendering tasks efficiently. To proceed with finding the best laptop for you, could you please specify if portability is a key factor for you? Do you require a laptop that is easy to carry around or do you primarily work from a stationary location?\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " I would need a good portable device for my work\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Thank you for clarifying that portability is important for you. A good portable device will help you work on-the-go with ease. To better understand your requirements, could you please specify your budget for the laptop? This will help me recommend options that fit within your price range while meeting your specified requirements.\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " I can stretch my budget to a maximum of 90000 rupees\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on your user profile and the provided product descriptions, here are the top recommended laptops for you:\n",
            "\n",
            "1. Lenovo ThinkPad : 60,000 INR, Ryzen 7 processor, 16GB RAM, 14\" IPS display (2560x1440), NVIDIA GTX graphics card, 1.6 kg, 3-year warranty, Battery life up to 6 hours\n",
            "\n",
            "2. Acer Predator : 80,000 INR, Intel Core i7 processor, 16GB RAM, 17.3\" IPS display (1920x1080), NVIDIA GTX graphics card, 3.2 kg, 1-year warranty, Battery life up to 5 hours\n",
            "\n",
            "3. MSI GL65 : 55,000 INR, Intel Core i7 processor, 16GB RAM, 15.6\" IPS display (1920x1080), NVIDIA GTX graphics card, 2.3 kg, 2-year warranty, Battery life up to 4 hours\n",
            "\n",
            "Now, let's match these laptops with your user profile:\n",
            "\n",
            "1. Lenovo ThinkPad:\n",
            "   - CPU: High (Ryzen 7 processor)\n",
            "   - GPU: Medium (NVIDIA GTX graphics card)\n",
            "   - Display Quality: High (14\" IPS display with 2560x1440 resolution)\n",
            "   - Portability: High (1.6 kg weight)\n",
            "   - Multitasking: Medium (16GB RAM)\n",
            "   - Within Budget\n",
            "\n",
            "2. Acer Predator:\n",
            "   - CPU: High (Intel Core i7 processor)\n",
            "   - GPU: Medium (NVIDIA GTX graphics card)\n",
            "   - Display Quality: High (17.3\" IPS display with 1920x1080 resolution)\n",
            "   - Portability: Medium (3.2 kg weight)\n",
            "   - Multitasking: Medium (16GB RAM)\n",
            "   - Slightly above Budget\n",
            "\n",
            "3. MSI GL65:\n",
            "   - CPU: High (Intel Core i7 processor)\n",
            "   - GPU: Medium (NVIDIA GTX graphics card)\n",
            "   - Display Quality: High (15.6\" IPS display with 1920x1080 resolution)\n",
            "   - Portability: High (2.3 kg weight)\n",
            "   - Multitasking: Medium (16GB RAM)\n",
            "   - Within Budget\n",
            "\n",
            "Based on your user profile and preferences, the Lenovo ThinkPad and MSI GL65 are suitable options. The Lenovo ThinkPad offers a high-quality display, portability, and strong CPU performance within your budget. The MSI GL65 also provides similar features and is a great value for money option.\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " exit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "I'm glad to have had the opportunity to assist you. If you have any more questions in the future, feel free to ask. Have a great day!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dialogue_mgmt_system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e39400-ca9c-4d4c-aa66-405eb283ef42",
      "metadata": {
        "id": "32e39400-ca9c-4d4c-aa66-405eb283ef42"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}